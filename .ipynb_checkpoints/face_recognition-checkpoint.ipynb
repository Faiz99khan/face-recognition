{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def face_extract(filename,required_size=(160,160)):  \n",
    "    image = Image.open(filename)    \n",
    "    image = image.convert('RGB')                # convert to RGB, if needed    \n",
    "    image = np.asarray(image)   \n",
    "    detector = MTCNN()                          # create the detector, using default weights  \n",
    "    results = detector.detect_faces(image)     # detect faces in the image    \n",
    "    if len(results):\n",
    "        faces,boxes=[],[]\n",
    "        for i in range(len(results)):\n",
    "            x1, y1, width, height = results[i]['box']    # extract the bounding box from the first face    \n",
    "            x1, y1 = abs(x1), abs(y1)\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            face = image[y1:y2, x1:x2]                  # extract the face\n",
    "            face=cv2.resize(face,required_size)\n",
    "            faces.append(face)\n",
    "            boxes.append([x1,y1,width,height])\n",
    "        return faces,boxes\n",
    "    else:\n",
    "        return ([],[]) \n",
    "    \n",
    "# load images and extract faces for all images in a directory\n",
    "def load_faces(directory):\n",
    "    faces_lst = list()  \n",
    "    for filename in listdir(directory):      \n",
    "        path = directory + filename\n",
    "        faces,_ = face_extract(path)                # get face\n",
    "        if len(faces):\n",
    "            faces_lst.append(faces[0])\n",
    "    return faces_lst\n",
    "\n",
    "\n",
    "# load a dataset that contains one subdir for each class that in turn contains images\n",
    "def load_dataset(directory):\n",
    "    X, y = list(), list()\n",
    "    people_dict={}\n",
    "    for i,subdir in enumerate(listdir(directory)):\n",
    "        path = directory + subdir + '/'        \n",
    "        if not isdir(path):               # skip any files that might be in the dir\n",
    "            continue\n",
    "        faces = load_faces(path)          # load all faces in the subdirectory\n",
    "        people_dict.update({i:subdir})    # create key to people dictionary\n",
    "        print('loaded %d images for person: %s' % (len(faces), subdir))\n",
    "        labels=[subdir for _ in range(len(faces))]\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return np.asarray(X), np.asarray(y),people_dict\n",
    "\n",
    "def face_to_embedding(face,model):\n",
    "        face = face.astype('float32')      \n",
    "        mean, std = face.mean(), face.std()\n",
    "        face_norm = (face - mean) / std        # normalize face pixels\n",
    "        face_norm = np.expand_dims(face_norm, axis=0)       \n",
    "        return model.predict(face_norm)        # make prediction to get embedding and return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create new database and train the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 26 images for person: Aamir\n",
      "loaded 22 images for person: Akshay\n",
      "loaded 20 images for person: Faiz\n",
      "loaded 13 images for person: Imran\n",
      "loaded 17 images for person: salman\n",
      "loaded 25 images for person: salman khan\n",
      "loaded 13 images for person: shahrukh\n",
      "x_train shape: (136, 160, 160, 3) \n",
      "y_train shape: (136,)\n",
      "model is loaded successfully\n",
      "embeddings & people dictionary are saved successfully\n",
      "Accuracy: train=100.000\n",
      "System is trained for face recognition sucessfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load train dataset\n",
    "x_train,y_train,people_dict = load_dataset('my_dataset/train/')\n",
    "print('x_train shape:',x_train.shape,'\\ny_train shape:', y_train.shape)\n",
    "\n",
    "people_to_key_dict={v:k for k,v in people_dict.items()}\n",
    "\n",
    "#load pre-trained facenet model\n",
    "embed_model=load_model('facenet_model/facenet_keras.h5')\n",
    "print('model is loaded successfully')\n",
    "\n",
    "#convert face to embedding\n",
    "x_train_embed=[]\n",
    "y_train_ls=[]\n",
    "for i in range(x_train.shape[0]):\n",
    "    embed=face_to_embedding(x_train[i],embed_model)\n",
    "    x_train_embed.append(embed)\n",
    "    y_train_ls.append(people_to_key_dict[y_train[i]])\n",
    "\n",
    "x_train_embed=np.asarray(x_train_embed).squeeze()\n",
    "y_train=np.asarray(y_train_ls).squeeze()\n",
    "\n",
    "# save embeddings in compressed format\n",
    "np.savez_compressed('database/people-embeddings.npz',x_train_embed, y_train)\n",
    "#save people dictionary \n",
    "joblib.dump(people_dict,'database/people_dictionary.pkl')\n",
    "print('embeddings & people dictionary are saved successfully')\n",
    "\n",
    "#normalize the embeddings\n",
    "l2_normalizer=Normalizer(norm='l2')\n",
    "x_train_embed=l2_normalizer.transform(x_train_embed)\n",
    "\n",
    "#shuffle the data\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(x_train_embed)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(y_train)\n",
    "\n",
    "#create SVC model and fit \n",
    "FR_model = SVC(kernel='linear', probability=True)\n",
    "FR_model.fit(x_train_embed,y_train)\n",
    "\n",
    "# predict\n",
    "yhat_train = FR_model.predict(x_train_embed)\n",
    "\n",
    "score_train = accuracy_score(y_train, yhat_train)\n",
    "print('Accuracy: train=%.3f' % (score_train*100))\n",
    "\n",
    "#save svc model\n",
    "joblib.dump(FR_model,'model/FR_model.pkl')\n",
    "print('System is trained for face recognition sucessfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add new person in the existing database and train the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the model and people dictionary\n",
    "#FR_model=joblib.load('model/FR_model.pkl')\n",
    "#embed_model=load_model('facenet_model/facenet_keras.h5')\n",
    "people_dict=joblib.load('database/people_dictionary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: train=100.000\n",
      "Hritik is added in the database sucessfully\n"
     ]
    }
   ],
   "source": [
    "#let's add another actor\n",
    "person_name='Hritik'\n",
    "directory_path='new_person/Hritik/'\n",
    "\n",
    "temp_dict=people_dict.copy()\n",
    "\n",
    "def add_new_person(person_name,dir_path):\n",
    "    new_key=len(temp_dict)\n",
    "    temp_dict[new_key]=person_name\n",
    "\n",
    "    #load faces\n",
    "    faces=load_faces(dir_path)\n",
    "\n",
    "    new_embed_set=[]\n",
    "    new_label_set=[]\n",
    "    for i in range(len(faces)):\n",
    "        embed=face_to_embedding(faces[i],embed_model)\n",
    "        new_embed_set.append(embed)\n",
    "        new_label_set.append(new_key)\n",
    "\n",
    "    new_embed_set=np.array(new_embed_set).squeeze()\n",
    "    new_label_set=np.array(new_label_set).squeeze()\n",
    "\n",
    "\n",
    "    data=np.load('database/people-embeddings.npz')\n",
    "    x_train_embed,y_train=data['arr_0'],data['arr_1']\n",
    "    x_train_embed=np.vstack((x_train_embed,new_embed_set))\n",
    "    y_train=np.concatenate((y_train,new_label_set))\n",
    "    \n",
    "    #normalize the embeddings\n",
    "    l2_normalizer=Normalizer(norm='l2')\n",
    "    x_train_embed=l2_normalizer.transform(x_train_embed)\n",
    "\n",
    "    #shuffle the data\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(x_train_embed)\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(y_train)\n",
    "\n",
    "    #create SVC model and fit \n",
    "    FR_model = SVC(kernel='linear', probability=True)\n",
    "    FR_model.fit(x_train_embed,y_train)\n",
    "\n",
    "    # predict\n",
    "    yhat_train = FR_model.predict(x_train_embed)\n",
    "\n",
    "    score_train = accuracy_score(y_train, yhat_train)\n",
    "    print('Accuracy: train=%.3f' % (score_train*100))\n",
    "    \n",
    "    people_dict=temp_dict.copy()\n",
    "    #save people dictionary \n",
    "    joblib.dump(people_dict,'database/people_dictionary.pkl')\n",
    "    \n",
    "    # save embeddings in compressed format\n",
    "    np.savez_compressed('database/people-embeddings.npz',x_train_embed, y_train)\n",
    "    \n",
    "    #save svc model\n",
    "    joblib.dump(FR_model,'model/FR_model.pkl')\n",
    "    \n",
    "    print('%s is added in the database sucessfully'%(person_name))\n",
    "    \n",
    "add_new_person(person_name,directory_path)\n",
    "people_dict=temp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "#load the model and people dictionary\n",
    "FR_model=joblib.load('model/FR_model.pkl')\n",
    "embed_model=load_model('facenet_model/facenet_keras.h5')\n",
    "people_dict=joblib.load('database/people_dictionary.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='faiz.jpg'\n",
    "def find_people(img_path,model,embed_model):\n",
    "    faces,boxes=face_extract(img_path)\n",
    "    if len(faces):\n",
    "        img=cv2.imread(image_path,1)\n",
    "        for i in range(len(faces)):\n",
    "            face,(x,y,w,h)=faces[i],boxes[i]\n",
    "            embed=face_to_embedding(face,embed_model)\n",
    "            Nembed=Normalizer(norm='l2').transform(embed)\n",
    "            pred=model.predict_proba(Nembed)\n",
    "            prob=pred[0][np.argmax(pred[0])]\n",
    "            label=people_dict[np.argmax(pred[0])]+(\" %.2f\"%(prob*100)) if prob >.65 else 'unknown'                      \n",
    "            cv2.rectangle(img,(x,y), (x+w,y+h), (255,255,0), 1)\n",
    "            cv2.putText(img,label, (int(x), int(y-15)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "        try:\n",
    "\n",
    "            cv2.imshow('image',img)\n",
    "            if cv2.waitKey(0)==ord('q'):\n",
    "                cv2.destroyAllWindows() \n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print('there is no face in the image')\n",
    "\n",
    "find_people(image_path,FR_model,embed_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### at real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('HaarCascade/haarcascade_frontalface_default.xml') #extract face feature\n",
    "cap=cv2.VideoCapture(0)\n",
    "try: \n",
    "    while True:\n",
    "        _,frame=cap.read()\n",
    "        faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "        if len(faces):\n",
    "            for face in faces:\n",
    "                    (x,y,w,h)=face\n",
    "                    face_img=frame[y:y+h,x:x+w]\n",
    "                    face_img=cv2.resize(face_img,(160,160))\n",
    "                    embed=face_to_embedding(face_img,embed_model)         \n",
    "                    Nembed=Normalizer(norm='l2').transform(embed.reshape(1,-1))\n",
    "                    pred=FR_model.predict_proba(Nembed)\n",
    "                    clas=np.argmax(pred[0])\n",
    "                    prob=pred[0][clas]\n",
    "                    if  prob >.45:\n",
    "                        label=people_dict[clas]+(\" %.2f\"%(prob*100))\n",
    "                    else:\n",
    "                        label='unknown'\n",
    "                    cv2.rectangle(frame, (x,y), (x+w,y+h), (255,255,0), 1)\n",
    "                    cv2.putText(frame,label, (int(x), int(y-15)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n",
    "        cv2.imshow('Face Recognition',frame)\n",
    "        if cv2.waitKey(1)==ord('q'):\n",
    "            break   \n",
    "finally:            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
